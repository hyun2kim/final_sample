import json
import pandas as pd
from datasets import load_dataset
from deep_translator import GoogleTranslator
from tqdm import tqdm
import time

def create_korean_gorilla_dataset(num_samples=10):
    print("ğŸš€ Gorilla ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘...")
    # Gorilla ë¦¬ë”ë³´ë“œ ë°ì´í„° ë¡œë“œ
    ds = load_dataset("gorilla-llm/Berkeley-Function-Calling-Leaderboard", split="train")
    
    # 'simple' ì¹´í…Œê³ ë¦¬ë§Œ í•„í„°ë§ (ì´ˆë³´ì í›ˆë ¨ìš©ìœ¼ë¡œ ê°€ì¥ ì í•©)
    # ë°ì´í„°ì…‹ êµ¬ì¡°ìƒ ast_eval ë“±ìœ¼ë¡œ í•„í„°ë§í•˜ê±°ë‚˜, ê·¸ëƒ¥ ì•ë¶€ë¶„ ë°ì´í„°ê°€ ë³´í†µ simpleì…ë‹ˆë‹¤.
    # ì—¬ê¸°ì„œëŠ” ë²”ìš©ì„±ì„ ìœ„í•´ ë¬´ì‘ìœ„ë¡œ ì„ì–´ì„œ ë½‘ì§€ ì•Šê³  ì•ì—ì„œë¶€í„° ê°€ì ¸ì˜µë‹ˆë‹¤.
    
    # ë²ˆì—­ê¸° ì´ˆê¸°í™”
    translator = GoogleTranslator(source='auto', target='ko')
    
    new_dataset = []
    
    print(f"ğŸ”„ {num_samples}ê°œì˜ ë°ì´í„°ë¥¼ í•œêµ­ì–´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤...")
    
    # ë°ì´í„° ë³€í™˜ ë£¨í”„
    for i in tqdm(range(num_samples)):
        item = ds[i]
        
        original_question = item['question']
        
        # 1. ì§ˆë¬¸ ë²ˆì—­ (ì˜ì–´ -> í•œêµ­ì–´)
        try:
            # ë²ˆì—­ API ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•´ 0.5ì´ˆ ëŒ€ê¸°
            time.sleep(0.5) 
            korean_question = translator.translate(original_question)
            
            # ë²ˆì—­ í’ˆì§ˆì´ ë”±ë”±í•  ìˆ˜ ìˆìœ¼ë‹ˆ ë‚˜ì¤‘ì— ì‚¬ëŒì´ ê²€ìˆ˜í•˜ë©´ ë” ì¢‹ìŠµë‹ˆë‹¤.
            # ì˜ˆ: "Get weather" -> "ë‚ ì”¨ë¥¼ ì–»ë‹¤" (X) -> "ë‚ ì”¨ ì•Œë ¤ì¤˜" (O)
            
        except Exception as e:
            print(f"âš ï¸ ë²ˆì—­ ì‹¤íŒ¨ (Index {i}): {e}")
            korean_question = original_question # ì‹¤íŒ¨í•˜ë©´ ê·¸ëƒ¥ ì˜ì–´ë¡œ ë‘ 
            
        # 2. ìƒˆë¡œìš´ ë°ì´í„° êµ¬ì¡° ìƒì„±
        new_entry = {
            "id": i,
            "category": "simple",
            "question_en": original_question, # ì›ë³¸ ì˜ì–´ ì§ˆë¬¸ (ì°¸ê³ ìš©)
            "question_ko": korean_question,   # ë²ˆì—­ëœ í•œêµ­ì–´ ì§ˆë¬¸ (ì´ê±¸ë¡œ í…ŒìŠ¤íŠ¸!)
            "function": item['function'],     # íˆ´ ìŠ¤í™ (ê·¸ëŒ€ë¡œ ë‘ )
            "ground_truth": item['ground_truth'] # ì •ë‹µ (ê·¸ëŒ€ë¡œ ë‘ )
        }
        
        new_dataset.append(new_entry)

    # 3. íŒŒì¼ë¡œ ì €ì¥
    output_filename = "korean_gorilla_sample.json"
    with open(output_filename, "w", encoding="utf-8") as f:
        json.dump(new_dataset, f, ensure_ascii=False, indent=4)
        
    print(f"\nâœ… ë³€í™˜ ì™„ë£Œ! '{output_filename}' íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("ğŸ“‚ ë‚´ìš©ì„ í™•ì¸í•´ë³´ì„¸ìš”. ì´ì œ ì´ê±¸ë¡œ RAG/Agentë¥¼ í…ŒìŠ¤íŠ¸í•˜ë©´ ë©ë‹ˆë‹¤.")

if __name__ == "__main__":
    create_korean_gorilla_dataset(num_samples=10) # ì›í•˜ëŠ” ë§Œí¼ ìˆ«ìë¥¼ ëŠ˜ë¦¬ì„¸ìš”
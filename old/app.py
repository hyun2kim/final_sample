import streamlit as st
import json
import os
import requests
import psutil
from datetime import datetime
from scripts.evaluator import AgentEvaluator

# --------------------------------------------------------------------------------
# Constants & File Paths (ë°ì´í„° ê²½ë¡œ ì„¤ì •)
# --------------------------------------------------------------------------------
BASE_DATA_DIR = r"c:\final\final_subject\data"

# ì›ë³¸(English) ê²½ë¡œ
BFCL_SIMPLE_EN = os.path.join(BASE_DATA_DIR, "merged_bfcl_simple.json")
WIKIQA_EN = os.path.join(BASE_DATA_DIR, "ragas-wikiqa", "data", "sample.json")
BFCL_MULTI_EN = os.path.join(BASE_DATA_DIR, "merged_bfcl_multi.json")
BFCL_IRRELEVANCE_EN = os.path.join(BASE_DATA_DIR, "BFCL_v3_irrelevance.json")

# í•œêµ­ì–´(Korean) ê²½ë¡œ
BFCL_SIMPLE_KO = os.path.join(BASE_DATA_DIR, "merged_bfcl_simple_ko.json")
WIKIQA_KO = os.path.join(BASE_DATA_DIR, "ragas-wikiqa", "data", "sample_ko.json")
BFCL_MULTI_KO = os.path.join(BASE_DATA_DIR, "merged_bfcl_multi_ko.json")
BFCL_IRRELEVANCE_KO = os.path.join(BASE_DATA_DIR, "merged_bfcl_irrelevance_ko.json")

# --------------------------------------------------------------------------------
# Streamlit Page Configuration (í˜ì´ì§€ ì„¤ì •)
# --------------------------------------------------------------------------------
st.set_page_config(
    page_title="Engineer RPG: AI ì—ì´ì „íŠ¸ ë§ˆìŠ¤í„° í´ë˜ìŠ¤",
    page_icon="ğŸ›¡ï¸",
    layout="wide"
)

# --------------------------------------------------------------------------------
# Sidebar - Infrastructure Monitor (ì¸í”„ë¼ ëª¨ë‹ˆí„°ë§ ë ˆì´ì–´)
# --------------------------------------------------------------------------------
st.sidebar.title("ğŸ—ï¸ Infrastructure Layer")
st.sidebar.markdown("---")

# 1. ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ (Monitoring ë ˆì´ì–´ ì¬í˜„)
st.sidebar.subheader("ğŸ“Š System Monitoring")
cpu_usage = psutil.cpu_percent()
mem_usage = psutil.virtual_memory().percent
st.sidebar.text(f"CPU Usage: {cpu_usage}%")
st.sidebar.progress(cpu_usage / 100)
st.sidebar.text(f"Memory Usage: {mem_usage}%")
st.sidebar.progress(mem_usage / 100)

# 2. ìŠ¤í† ë¦¬ì§€ í˜„í™© (S3/Disk ë ˆì´ì–´ ì¬í˜„)
st.sidebar.subheader("ğŸ’¾ Storage (S3 Mock)")
files = [f for f in os.listdir(BASE_DATA_DIR) if f.endswith('.json')]
total_size = sum(os.path.getsize(os.path.join(BASE_DATA_DIR, f)) for f in files)
st.sidebar.caption(f"ì´ {len(files)}ê°œì˜ ë°ì´í„°ì…‹ ë¡œë“œë¨")
st.sidebar.caption(f"ì „ì²´ í¬ê¸°: {total_size / 1024:.1f} KB")

# 3. ë¹„ë™ê¸° í (Kafka Mock)
st.sidebar.subheader("ğŸ“¨ Task Queue (Kafka)")
st.sidebar.success("â— Queue Status: Healthy")
st.sidebar.caption("Active Workers: 4")

st.sidebar.markdown("---")
# --------------------------------------------------------------------------------
# Sidebar - Global Settings (ì „ì—­ ì„¤ì • ì°½)
# --------------------------------------------------------------------------------
st.sidebar.title("âš™ï¸ ì‹œìŠ¤í…œ ì„¤ì •")
language = st.sidebar.radio("ğŸŒ ì–¸ì–´ ì„ íƒ (Language)", ["í•œêµ­ì–´ (KO)", "English (EN)"])
lang_key = "ko" if language == "í•œêµ­ì–´ (KO)" else "en"

st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ”Œ API ì—°ë™ (Beta)")
api_type = st.sidebar.selectbox("LLM ì œê³µì", ["ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ", "OpenAI (GPT-4o)", "Google (Gemini 1.5 Pro)"])
api_key = st.sidebar.text_input("API Key ì…ë ¥", type="password")

# --------------------------------------------------------------------------------
# Data Loading Functions (ë°ì´í„° ë¡œë”© ë° ìºì‹±)
# --------------------------------------------------------------------------------
@st.cache_data
def load_json_data(file_path):
    if not os.path.exists(file_path):
        return []
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)

@st.cache_data
def load_irrelevance_data(file_path):
    if not os.path.exists(file_path): return []
    # Ko ë²„ì „ì€ ì´ë¯¸ JSON Arrayë¡œ ì €ì¥ë¨ (scripts/translate_to_ko.py ê²°ê³¼)
    if "_ko.json" in file_path:
        return load_json_data(file_path)
    
    # ì›ë³¸ En ë²„ì „ì€ JSONL í˜•ì‹ì„
    data = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                try: data.append(json.loads(line))
                except: pass
    return data

# í˜„ì¬ ì„ íƒëœ ì–¸ì–´ì— ë§ì¶° ë°ì´í„° ë¡œë“œ
# --------------------------------------------------------------------------------
# LLM API Interaction (Auto-Submission ë ˆì´ì–´)
# --------------------------------------------------------------------------------
def call_llm(prompt, system_prompt="ë‹¹ì‹ ì€ ìœ ëŠ¥í•œ AI ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤."):
    """ì‹¤ì œ LLM APIë¥¼ í˜¸ì¶œí•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤ (Auto-Submission)."""
    if api_type == "ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ":
        st.info("ğŸ’¡ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ: ì •ë‹µ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ìƒì˜ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.")
        return "SIMULATED_RESPONSE"
    
    if not api_key:
        st.warning("âš ï¸ ì‚¬ì´ë“œë°”ì—ì„œ API Keyë¥¼ ì…ë ¥í•´ì•¼ ìë™ ì œì¶œì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        return None
        
    try:
        if "OpenAI" in api_type:
            from openai import OpenAI
            client = OpenAI(api_key=api_key)
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ],
                temperature=0
            )
            return response.choices[0].message.content
        elif "Google" in api_type:
            return "Gemini API ì—°ë™ ì¤€ë¹„ ì¤‘..."
    except Exception as e:
        st.error(f"âŒ API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return None

# í˜„ì¬ ì„ íƒëœ ì–¸ì–´ì— ë§ì¶° ë°ì´í„° ë¡œë“œ
simple_data = load_json_data(BFCL_SIMPLE_KO if lang_key == "ko" else BFCL_SIMPLE_EN)
rag_data = load_json_data(WIKIQA_KO if lang_key == "ko" else WIKIQA_EN)
multi_data = load_json_data(BFCL_MULTI_KO if lang_key == "ko" else BFCL_MULTI_EN)
irr_data = load_irrelevance_data(BFCL_IRRELEVANCE_KO if lang_key == "ko" else BFCL_IRRELEVANCE_EN)

evaluator = AgentEvaluator()

# --------------------------------------------------------------------------------
# Main UI - Header
# --------------------------------------------------------------------------------
st.title("ğŸ›¡ï¸ Engineer RPG: AI ì—ì´ì „íŠ¸ ë§ˆìŠ¤í„° í´ë˜ìŠ¤")
st.markdown("""
ìµœê³ ì˜ AI ì—”ì§€ë‹ˆì–´ê°€ ë˜ê¸° ìœ„í•œ ì‹¤ì „ ì½”ìŠ¤ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤. 
ê° ë‹¨ê³„ì˜ í€˜ìŠ¤íŠ¸ë¥¼ í•´ê²°í•˜ë©° ì—ì´ì „íŠ¸ì˜ **ì •í™•ë„, ì‹ ë¢°ì„±, ì•ˆì „ì„±**ì„ ì™„ì„±í•´ ë³´ì„¸ìš”.
""")
# ë©”ì¸ ê¸°ëŠ¥ íƒ­ êµ¬ì„±
tabs = st.tabs(["ğŸ”§ Tool Calling", "ğŸ“š RAG ìµœì í™”", "ğŸ›¡ï¸ ê°€ë“œë ˆì¼(ë³´ì•ˆ)", "ğŸ”„ ë©€í‹°í„´ ëŒ€í™”", "ğŸ§ª ì•ˆì •í™” ì‹¤í—˜ì‹¤"])

# --------------------------------------------------------------------------------
# Tab 1: Tool Calling
# --------------------------------------------------------------------------------
with tabs[0]:
    st.subheader("ë¯¸ì…˜: í•¨ìˆ˜ í˜¸ì¶œ ì¸ìê°’ ìµœì í™”")
    if not simple_data:
        st.warning("Tool Calling ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        q_idx = st.select_slider("í€˜ìŠ¤íŠ¸ ë²ˆí˜¸", options=range(len(simple_data)), key="simple_slider")
        quest = simple_data[q_idx]
        c1, c2 = st.columns(2)
        with c1:
            st.info(f"**ì‚¬ìš©ì ìš”ì²­:** {quest['question'][0][0]['content']}")
            with st.expander("ğŸ› ï¸ ë„êµ¬ ëª…ì„¸(JSON Schema)"):
                st.json(quest['function'])
        with c2:
            st.write("**ëª¨ë¸ ì¶œë ¥ ë° í‰ê°€**")
            
            # Auto-Submission ê¸°ëŠ¥
            if st.button("ğŸ¤– AIì—ê²Œ ëŒ€ì‹  ë¬¼ì–´ë³´ê¸° (Auto-Submission)", key="ai_btn_simple"):
                with st.spinner("AIê°€ ê³ ë¯¼ ì¤‘..."):
                    sys_p = f"ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ë„êµ¬ ëª…ì„¸ {quest['function']}ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ìš”ì²­ì— ì•Œë§ì€ JSON í•¨ìˆ˜ í˜¸ì¶œë¬¸ì„ ìƒì„±í•˜ëŠ” ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µí•˜ì„¸ìš”."
                    ai_res = call_llm(quest['question'][0][0]['content'], sys_p)
                    if ai_res:
                        # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë©´ ì •ë‹µì„ ì‚´ì§ ë³´ì—¬ì¤Œ
                        if ai_res == "SIMULATED_RESPONSE":
                            ai_res = json.dumps(quest['ground_truth'][0])
                        st.session_state['res_simple'] = ai_res

            user_res = st.text_area("ê²°ê³¼ JSON", value=st.session_state.get('res_simple', ""), height=150, key="res_simple_input")
            
            if st.button("ğŸš€ ì„±ëŠ¥ í‰ê°€ ì‹¤í–‰", key="btn_simple"):
                report = evaluator.evaluate_tool_calling(user_res, quest['ground_truth'])
                if report['status'] == "í†µê³¼": 
                    st.success(f"ì„±ê³µ! ì ìˆ˜: {report['score']}%")
                else: 
                    err_msg = ", ".join(report.get('errors', [report.get('reason', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')]))
                    st.error(f"ì‹¤íŒ¨ (ì ìˆ˜: {report['score']}%): {err_msg}")

# --------------------------------------------------------------------------------
# Tab 2: RAG ìµœì í™”
# --------------------------------------------------------------------------------
with tabs[1]:
    st.subheader("ë¯¸ì…˜: RAG ì‹œìŠ¤í…œì˜ í™˜ê°(Hallucination) ë°©ì œ")
    if not rag_data:
        st.warning("RAG ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        r_idx = st.selectbox("ì‹¤ìŠµ ì¼€ì´ìŠ¤ ì„ íƒ", options=range(len(rag_data)), format_func=lambda x: f"Case {x}: {rag_data[x]['question'][:40]}")
        r_quest = rag_data[r_idx]
        c1, c2 = st.columns(2)
        with c1:
            st.warning(f"**ê²€ìƒ‰ëœ ì§€ì‹(Context):**\n\n{r_quest['context']}")
            st.info(f"**ì§ˆë¬¸:** {r_quest['question']}")
        with c2:
            st.write("**ì—ì´ì „íŠ¸ ë‹µë³€ ë° í‰ê°€**")
            
            # Auto-Submission ê¸°ëŠ¥
            if st.button("ğŸ¤– AIì—ê²Œ ëŒ€ì‹  ë¬¼ì–´ë³´ê¸° (Auto-Submission)", key="ai_btn_rag"):
                with st.spinner("AIê°€ ë¬¸ë§¥ì„ ì½ëŠ” ì¤‘..."):
                    sys_p = f"ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ì§€ì‹(Context)ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” RAG ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. ë¬¸ë§¥ì— ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”."
                    prompt = f"Context: {r_quest['context']}\n\nQuestion: {r_quest['question']}"
                    ai_res = call_llm(prompt, sys_p)
                    if ai_res:
                        if ai_res == "SIMULATED_RESPONSE":
                            ai_res = r_quest['correct_answer']
                        st.session_state['res_rag'] = ai_res

            r_ans = st.text_area("ì—ì´ì „íŠ¸ ë‹µë³€", value=st.session_state.get('res_rag', ""), height=150, key="res_rag_input")
            
            if st.button("âš–ï¸ RAG í‰ê°€ ì§€í‘œ ì¸¡ì •", key="btn_rag"):
                report = evaluator.evaluate_rag(r_ans, r_quest['correct_answer'], r_quest['context'])
                st.metric("ì¢…í•© ì‹ ë¢°ë„ ì ìˆ˜", f"{report['score']}%")

# --------------------------------------------------------------------------------
# Tab 3: ê°€ë“œë ˆì¼ (ë¬´ê´€ ì§ˆë¬¸ íƒì§€)
# --------------------------------------------------------------------------------
with tabs[2]:
    st.subheader("ë¯¸ì…˜: ì—ì´ì „íŠ¸ ê°€ë“œë ˆì¼ êµ¬ì¶•")
    if not irr_data:
        st.warning("ê°€ë“œë ˆì¼ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        i_idx = st.select_slider("ê°€ë“œë ˆì¼ ì‹œë‚˜ë¦¬ì˜¤", options=range(len(irr_data)), key="irr_slider")
        i_quest = irr_data[i_idx]
        c1, c2 = st.columns(2)
        with c1:
            st.info(f"**ë¬´ê´€í•œ ì‚¬ìš©ì ì§ˆë¬¸:** {i_quest['question'][0][0]['content']}")
            st.warning(f"**ì œê³µëœ ë„êµ¬ (ì´ ì§ˆë¬¸ê³¼ ë¬´ê´€í•¨):** {i_quest['function'][0]['name']}")
        with c2:
            st.write("**ëª¨ë¸ ì‘ë‹µ ë° ê²€ì¦**")

            # Auto-Submission ê¸°ëŠ¥
            if st.button("ğŸ¤– AIì—ê²Œ ëŒ€ì‹  ë¬¼ì–´ë³´ê¸° (Auto-Submission)", key="ai_btn_irr"):
                with st.spinner("AIê°€ ë³´ì•ˆ ê²€ì‚¬ ì¤‘..."):
                    sys_p = f"ë‹¹ì‹ ì€ ë³´ì•ˆ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë„êµ¬ {i_quest['function']}ë¡œ í•´ê²°í•  ìˆ˜ ì—†ëŠ” ìš”ì²­ì€ ê±°ì ˆí•´ì•¼ í•©ë‹ˆë‹¤. ì ˆëŒ€ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ì§€ ë§ˆì„¸ìš”."
                    ai_res = call_llm(i_quest['question'][0][0]['content'], sys_p)
                    if ai_res:
                        if ai_res == "SIMULATED_RESPONSE":
                            ai_res = "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­í•˜ì‹  ê¸°ëŠ¥ì€ ì œê³µë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
                        st.session_state['res_irr'] = ai_res

            i_res = st.text_area("ëª¨ë¸ ì‘ë‹µ (ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ë©´ ì‹¤íŒ¨)", value=st.session_state.get('res_irr', ""), height=150, key="res_irr_input")
            
            if st.button("ğŸš” ê°€ë“œë ˆì¼ ê²€ì¦", key="btn_irr"):
                report = evaluator.evaluate_guardrail(i_res, is_irrelevance=True)
                if report['status'] == "í†µê³¼": st.success(report['reason'])
                else: st.error(report['reason'])

# --------------------------------------------------------------------------------
# Tab 4: ë©€í‹°í„´ (ëŒ€í™” ë¬¸ë§¥ ìœ ì§€)
# --------------------------------------------------------------------------------
with tabs[3]:
    st.subheader("ë¯¸ì…˜: ë©€í‹°í„´ ëŒ€í™” ì‹œë‚˜ë¦¬ì˜¤ í•´ê²°")
    if not multi_data:
        st.warning("ë©€í‹°í„´ ì‹¤ì „ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        m_idx = st.selectbox("ë©€í‹°í„´ í”„ë¡œì íŠ¸ ì„ íƒ", options=range(len(multi_data)))
        m_quest = multi_data[m_idx]
        turn_num = st.radio("í˜„ì¬ ëŒ€í™” í„´(Turn) ì„ íƒ", options=range(len(m_quest['question'])), horizontal=True)
        st.info(f"**í˜„ì¬ í„´ ì§ˆë¬¸:** {m_quest['question'][turn_num][0]['content']}")
        st.write(f"**ì´ í„´ì˜ ì •ë‹µ ê°€ì´ë“œ:** {m_quest['ground_truth'][turn_num]}")

# --------------------------------------------------------------------------------
# Tab 5: ì•ˆì •í™” ì‹¤í—˜ì‹¤ (Self-Correction)
# --------------------------------------------------------------------------------
with tabs[4]:
    st.subheader("ğŸ•µï¸ ì—ì´ì „íŠ¸ ì•ˆì •í™” ì‹¤í—˜ì‹¤ (Hallucination Stabilization)")
    st.write("ì´ˆì•ˆì˜ í™˜ê°ì„ ì¡ê³  ìµœì¢… ë‹µë³€ì„ ì•ˆì •í™”í•˜ëŠ” 'ìê¸° ìˆ˜ì •' ë£¨í”„ë¥¼ ì‹¤ìŠµí•©ë‹ˆë‹¤.")
    
    # RAG ë°ì´í„° ê³µìœ  ì‚¬ìš©
    if not rag_data:
        st.warning("ë¹„êµ ëŒ€ìƒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        s_idx = st.selectbox("ì•ˆì •í™” í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤", options=range(len(rag_data)), key="s_idx")
        s_quest = rag_data[s_idx]
        
        st.warning(f"**ì œê³µëœ ê·¼ê±°(Context):**\n\n{s_quest['context']}")
        
        sc1, sc2 = st.columns(2)
        with sc1:
            st.info("1ë‹¨ê³„: ì´ˆì•ˆ ì‘ì„± (í™˜ê° í¬í•¨ ê°€ëŠ¥ì„±)")
            draft_ans = st.text_area("ì´ˆì•ˆ ë‹µë³€ (Draft Answer)", 
                                     value="ì´ê²ƒì€ ì´ˆì•ˆì…ë‹ˆë‹¤. ë¬¸ë§¥ì— ì—†ëŠ” ë‚´ìš©ì´ í¬í•¨ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.", 
                                     height=150, key="draft_ans")
        
        with sc2:
            st.success("2ë‹¨ê³„: ìµœì¢…ë³¸ ì‘ì„± (ì•ˆì •í™” ì™„ë£Œ)")
            final_ans = st.text_area("ìµœì¢… ë‹µë³€ (Stabilized Answer)", 
                                     value=s_quest['correct_answer'], 
                                     height=150, key="final_ans")
            
        if st.button("âš–ï¸ ì•ˆì •í™” ì„±ëŠ¥ ë¹„êµ", key="btn_stable"):
            report = evaluator.evaluate_staged_rag(draft_ans, final_ans, s_quest['context'])
            
            c_m1, c_m2, c_m3 = st.columns(3)
            c_m1.metric("ì´ˆì•ˆ ì ìˆ˜", f"{report['draft_score']}%")
            c_m2.metric("ìµœì¢… ì ìˆ˜", f"{report['final_score']}%")
            c_m3.metric("í–¥ìƒë„", f"+{report['improvement']}%")
            
            if report['improvement'] > 0:
                st.success(f"ğŸ‰ {report['feedback']}")
            else:
                st.warning(f"âš ï¸ {report['feedback']}")

st.sidebar.markdown("---")
st.sidebar.caption("Â© 2026 Engineer RPG Framework.")
